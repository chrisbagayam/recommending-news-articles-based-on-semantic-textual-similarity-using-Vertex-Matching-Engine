{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f079e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f09c73-1cd5-46f0-98bd-9f1d3ca30a68",
   "metadata": {},
   "source": [
    "<h3>Recommending News Articles based on semantic textual similarity using Vertex Matching Engine</h3>\n",
    "\n",
    "<h4> Overview</h4>\n",
    "<p>This is the implementation of a recommendation System discussed in this <a href=\"url\">blog post</a></p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca2a6d8-854f-469d-a853-2cdc387c5071",
   "metadata": {},
   "source": [
    "<h3>Before you begin</h3>\n",
    "\n",
    "<h4>Set your project ID</h4>\n",
    "If you don't know your project ID, try the following:\n",
    "<ul>\n",
    "    <li>Run gcloud config list.</li>\n",
    "    <li>Run gcloud projects list.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c14da-0fca-452c-a5e4-0e5ae392b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[YOUR-PROJECT-ID]\"\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f47a6d-1245-4dfd-954d-c76233af6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "from typing import Type\n",
    "import apache_beam as beam\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "from apache_beam.pipeline import PipelineOptions\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "REGION = \"us-west1\"\n",
    "# BUCKET_NAME=\"gs://dataflow_blog_example_bct/embeddings/prediction-universal_encoder_embedding_model_01-2023_03_09T10_56_00_808Z\"\n",
    "BUCKET_NAME=\"gs://me101chris\"\n",
    "DEPLOYED_MODEL_ID=\"7666164504761204736\"\n",
    "\n",
    "ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "PARENT = \"projects/{}/locations/{}\".format(PROJECT_ID, REGION)\n",
    "DIMENSIONS = 512 # the embeddings dim from the model\n",
    "DISPLAY_NAME = \"similar_article_index\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52cedaaf-738a-40d4-a8f0-e8b0c6e56d43",
   "metadata": {},
   "source": [
    "<h3>Data Ingestion</h3>\n",
    "Note: we have downloaded the public <a href='https://www.kaggle.com/datasets/rmisra/news-category-dataset'>news category dataset</a> from Kaggle datasets and stored the data file in the GCS bucket. \n",
    "<ul>\n",
    "    <li>Read the txt files stored in Google Cloud Storage,</li>\n",
    "    <li>Parse the files, remove special characters and concatenate the title and body.</li>\n",
    "    <li>Write the transformed data into GCS in a JSONL format (i.e. prediction input instances) that Vertex AI consumes as input for batch prediction jobs.\n",
    "</li>\n",
    "\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb04c0b2-64f0-48df-8855-2601325ff226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data: str) -> Dict:\n",
    "    data = json.loads(data)\n",
    "    data[\"text\"] =  data[\"headline\"] + \" \" + data[\"short_description\"]\n",
    "    filtered_char = [ \"\\t\", \"\\0\", \"\\a\", \"\\b\", \"\\f\", \"\\r\", \"\\x0b\", \"\\x0c\", '\"', \"\\xa0\", \"\\n\", \"\\xad\", \"\\x99\", \"\\x94\", \"\\x93\", \"\\x80\", \"\\x7f\" ]\n",
    "\n",
    "    for char in filtered_char:\n",
    "        data[\"text\"] = data[\"text\"].replace(char, \"\")\n",
    "\n",
    "    data[\"text\"] = data[\"text\"].replace('\"\\\"', \"\")\n",
    "    data[\"text\"] = data[\"text\"].replace(\"'\", \"##\")\n",
    "  \n",
    "    yield {\n",
    "        \"article_id\": data[\"link\"],\n",
    "        \"bytes_inputs\": data[\"text\"] \n",
    "    }\n",
    "\n",
    "def build_pipeline(pipeline: Type[beam.Pipeline]):\n",
    "    \"\"\"Builds Apache Beam pipeline.\"\"\"\n",
    "\n",
    "    # Setting the data source and target\n",
    "    articles_source_csv_file =\"gs://dataflow_blog_example_bct/News_Category_Dataset_v3.json\" \n",
    "    \n",
    "    # Read article jsonl files from gcs\n",
    "    steps = (pipeline\n",
    "            | \"Read article file\" >> beam.io.ReadFromText(articles_source_csv_file, skip_header_lines=1)\n",
    "            | \"Parse article parse\" >> beam.ParDo(process) \n",
    "            | \"change char 1\" >> beam.Map(lambda x: str(x).replace(\"'\", '\"'))\n",
    "            | \"change char 2\" >> beam.Map(lambda x: str(x).replace(\"##\", \"'\"))\n",
    "            |\"Write instances to jsonl\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=\"gs://dataflow_blog_example_bct/instances/instances\", file_name_suffix=\".jsonl\"\n",
    "            )\n",
    "             \n",
    "            )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "763107f1-d22a-4b10-8cd9-662548d62a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-a9c1369d-4e74-4f03-82f4-0d9c710a452e.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-a9c1369d-4e74-4f03-82f4-0d9c710a452e.json']\n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "options = PipelineOptions(\n",
    "    runner = \"DataflowRunner\",\n",
    "    project=PROJECT_ID,\n",
    "    temp_location=\"gs://dataflow_blog_example_bct/temp\",\n",
    "    region=REGION\n",
    ")\n",
    "\n",
    "with beam.Pipeline(options=options) as pipeline:\n",
    "    build_pipeline(pipeline)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77ac54f8-718c-4df3-b9fe-65e5ff13e064",
   "metadata": {},
   "source": [
    "<h3>Change of Model Signature with customized  output format</h3>\n",
    "Note: we have downloaded the <a href='https://tfhub.dev/google/universal-sentence-encoder/4'>sentence encoder model</a> files and stored in the GCS bucket.<br> \n",
    "This function takes the original model, changes the output format (i.e. outputs from TensorFlow saved model signature) by adding the article_id, and saves a new copy as a 'wrapped' version in GCS.<br>\n",
    "Eg: {\"article_id\": article_id,\"embedding\": [1,1,1,1,1,...]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "253383c1-a064-4531-b1df-8dcf9b6cd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "INFO:tensorflow:Assets written to: gs://dataflow_blog_example_bct/universal-sentence-encoder_4/wrapped_model/assets\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def model_change_signature(model_path: str) -> None:\n",
    "\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    def _get_serve_fn(model):\n",
    "        @tf.function\n",
    "        def serve_fn(bytes_inputs, article_id):\n",
    "            \n",
    "            vector = model(bytes_inputs)\n",
    "\n",
    "            return {\n",
    "                \"article_id\": article_id,\n",
    "                \"embedding_vector\": vector\n",
    "            }\n",
    "        return serve_fn\n",
    "\n",
    "    signatures = {\n",
    "        \"serving_default\": _get_serve_fn(model).get_concrete_function(\n",
    "            # input text\n",
    "            tf.TensorSpec(shape=[None], dtype=tf.string),\n",
    "            # input article ID\n",
    "            tf.TensorSpec(shape=[None], dtype=tf.string)\n",
    "        )\n",
    "    }\n",
    "    tf.saved_model.save(model, os.path.join(model_path , 'wrapped_model') , signatures=signatures)\n",
    "\n",
    "print(\"starting...\")\n",
    "model_change_signature(\"gs://dataflow_blog_example_bct/universal-sentence-encoder_4/\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4c902-785f-4bbb-8a25-7cf4493e03e7",
   "metadata": {},
   "source": [
    "<h3>Upload the embedding model to Vertex AI</h3>\n",
    "After upload, you can perform batch prediction. \n",
    "However, for stream prediction, you need to deploy the model to an endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cba8584b-159f-4410-a3cb-acabbe548ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/543051426883/locations/us-west1/models/7666164504761204736/operations/671148494664237056\n",
      "Model created. Resource name: projects/543051426883/locations/us-west1/models/7666164504761204736@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/543051426883/locations/us-west1/models/7666164504761204736@1')\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Upload the embedding model to GCP\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=\"universal_encoder_embedding_model_01\",\n",
    "    artifact_uri=BUCKET_NAME+\"/universal-sentence-encoder_4/wrapped_model\",\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\",\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11de6a-ba41-4517-9aca-48a17161d98f",
   "metadata": {},
   "source": [
    "<h3> Running Embedding model batch prediction</h3>\n",
    "\n",
    "This batch prediction job will help us to transform all the articles into embeddings and save them in GCS in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead2015-75c2-46d5-8a4c-2f439c30bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_endpoint = REGION+\"-aiplatform.googleapis.com\"\n",
    "client_options = {\"api_endpoint\": api_endpoint}\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "client = aiplatform.gapic.JobServiceClient(\n",
    "    client_options=client_options\n",
    ")\n",
    "model = aiplatform.Model(DEPLOYED_MODEL_ID)\n",
    "batch_prediction_job = {\n",
    "    \"display_name\": \"prediting embeddings\",\n",
    "    \"model\": model.resource_name,\n",
    "    \"input_config\": {\n",
    "        \"instances_format\": \"jsonl\",\n",
    "        \"gcs_source\": {\"uris\": [BUCKET_NAME+\"/instances/instances-00000-of-00001.jsonl\"]},\n",
    "    },\n",
    "    \"output_config\": {\n",
    "        \"predictions_format\": \"jsonl\",\n",
    "        \"gcs_destination\": {\"output_uri_prefix\": BUCKET_NAME+\"/embeddings/\"},\n",
    "    },\n",
    "    \"dedicated_resources\": {\n",
    "        \"machine_spec\": {\n",
    "             \"machine_type\": \"n1-standard-32\",\n",
    "             # \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "             # \"accelerator_count\": 2,\n",
    "        },\n",
    "        \"starting_replica_count\": 2,\n",
    "        \"max_replica_count\":2,\n",
    "    },\n",
    "    \"manual_batch_tuning_parameters\": {\n",
    "        # The default batch size is 4.   \n",
    "        \"batch_size\": 5\n",
    "    },\n",
    "}\n",
    "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "\n",
    "job = client.create_batch_prediction_job(\n",
    "    parent=parent, batch_prediction_job=batch_prediction_job\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b26ab2-00f8-46ab-9c7b-6e7f69ec777a",
   "metadata": {},
   "source": [
    "<h3>Serve the embedding model to an online prediction endpoint </h3>\n",
    "\n",
    "<p>you cannot perform real time prediction without deploying your model to an endpoint on Vertex AI.</p>\n",
    "\n",
    "<p>This step come in handy in production when we expect to receive one article at a time, map it to an embedding and query similar ones.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54f5040e-5d77-4f5e-b006-19c6181ab7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/543051426883/locations/us-west1/endpoints/2293370149308203008/operations/4677100363210293248\n",
      "Endpoint created. Resource name: projects/543051426883/locations/us-west1/endpoints/2293370149308203008\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/543051426883/locations/us-west1/endpoints/2293370149308203008')\n",
      "Deploying Model projects/543051426883/locations/us-west1/models/7666164504761204736 to Endpoint : projects/543051426883/locations/us-west1/endpoints/2293370149308203008\n",
      "Deploy Endpoint model backing LRO: projects/543051426883/locations/us-west1/endpoints/2293370149308203008/operations/6942410975777652736\n",
      "Endpoint model deployed. Resource name: projects/543051426883/locations/us-west1/endpoints/2293370149308203008\n"
     ]
    }
   ],
   "source": [
    "project = PROJECT_ID\n",
    "location = REGION\n",
    "display_name=\"Universal_encoder_endpoint_01\"\n",
    "\n",
    "machine_type= \"n1-standard\"\n",
    "vcpu= \"16\"\n",
    "\n",
    "\n",
    "endpoint = aiplatform.Endpoint.create(\n",
    "        display_name=display_name,\n",
    "        project=PROJECT_ID,\n",
    "        location=REGION,\n",
    "        )\n",
    "_ = endpoint.deploy(model=model,deployed_model_display_name=display_name, machine_type= machine_type + \"-\" + vcpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea567d4-e3fb-4f85-89dc-cf42dcca3378",
   "metadata": {},
   "source": [
    "<h3>Creating A Matching Engine Index</h3>\n",
    "\n",
    "<p>Before creating an index, we need to address one more thing: Matching Engine expect an input of the format { \"id\":\"\", \"embedding\":[1,1,...]}.</p> <p>However, the batch prediction result from the previous step is stored in a different format i.e {\"instance\": {\"article_id\": \"\", \"bytes_inputs\": \"\"}, \"prediction\": {\"article_id\": \"\", \"embedding_vector\": [-0.0030, -0.06,..]}},</p>\n",
    "\n",
    "<p>The following pipepiline put the data in the right format for index creation </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dea57a-39f0-4aaa-b950-0e32ead686c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare embeddings for index creation\n",
    "def process(data):\n",
    "    \n",
    "    data = json.loads(data)\n",
    "    data = data[\"prediction\"]\n",
    "    # print(data[\"prediction\"])\n",
    "    # print(data)\n",
    "    yield {\n",
    "        \"id\": data[\"article_id\"],\n",
    "        \"embedding\": data[\"embedding_vector\"] \n",
    "    }\n",
    "\n",
    "def build_pipeline(pipeline: Type[beam.Pipeline]):\n",
    "    \"\"\"Builds Apache Beam pipeline.\"\"\"\n",
    "\n",
    "    # Setting the data source and target\n",
    "    # articles_source_json_file = config.get(\"articles_source_dir\")\n",
    "    embedding_source = BUCKET_NAME+\"/embeddings/prediction-universal_encoder_embedding_model_01-2023_03_10T10_24_23_312Z\"\n",
    "    embedding_source_json_file = os.path.join(\n",
    "        embedding_source, 'prediction.results-*')\n",
    "\n",
    "    # Read article jsonl files from gcs\n",
    "    steps = (pipeline\n",
    "             |beam.io.ReadFromText(embedding_source_json_file)\n",
    "             | \"Parse article parse\" >> beam.ParDo(process) \n",
    "             # |'format json' >> beam.Map(json.dumps)\n",
    "             #|beam.Map(lambda item: {\"id\": item[\"id\"], \"embedding\": item[\"embedding\"]})\n",
    "             | \"Write instances to jsonl\" >> beam.io.WriteToText(\n",
    "                file_path_prefix=BUCKET_NAME+\"/vector_embeddings/\", file_name_suffix=\".json\", num_shards=20,shard_name_template=\"-SSSSS-of-NNNNN\"\n",
    "            )\n",
    "        )\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9932f-9bcb-4650-a9b4-ded4d4108a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "options = PipelineOptions(\n",
    "    # runner = \"DataflowRunner\",\n",
    "    project=PROJECT_ID,\n",
    "    temp_location=BUCKET_NAME+\"/temp\",\n",
    "    region=REGION\n",
    ")\n",
    "\n",
    "with beam.Pipeline(options=options) as pipeline:\n",
    "    build_pipeline(pipeline)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f22f714-261f-42e2-8e14-ed8bffb76042",
   "metadata": {},
   "source": [
    "<h4>Create The Matching Engine Index</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b18f0-672a-4914-a0ca-0ea14dfd49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Index\n",
    "\n",
    "def create_index(brute_force=False, stream_update=True):\n",
    "    #instantiate client handler\n",
    "    index_client = aiplatform_v1.IndexServiceClient(\n",
    "            client_options=dict(api_endpoint=ENDPOINT)\n",
    "        )\n",
    "\n",
    "\n",
    "    # set the algorithm to brute force or ANN\n",
    "    if brute_force:\n",
    "        algorithmConfig = struct_pb2.Struct(fields={ \n",
    "        \"bruteForceConfig\": struct_pb2.Value(struct_value=struct_pb2.Struct())})\n",
    "\n",
    "    else: # ANN algorithm\n",
    "        treeAhConfig = struct_pb2.Struct(fields={\n",
    "        \"leafNodeEmbeddingCount\": struct_pb2.Value(number_value=500),\n",
    "        \"leafNodesToSearchPercent\": struct_pb2.Value(number_value=10) \n",
    "        })\n",
    "        algorithmConfig = struct_pb2.Struct(fields={ \n",
    "        \"treeAhConfig\": struct_pb2.Value(struct_value=treeAhConfig)})\n",
    "\n",
    "    # create the index config       \n",
    "    index_config = struct_pb2.Struct(fields={\n",
    "        \"dimensions\": struct_pb2.Value(number_value=DIMENSIONS),\n",
    "        \"approximateNeighborsCount\": struct_pb2.Value(number_value=150),\n",
    "        \"distanceMeasureType\": struct_pb2.Value(string_value=\"COSINE_DISTANCE\"),\n",
    "        \"algorithmConfig\": struct_pb2.Value(struct_value=algorithmConfig)\n",
    "    })\n",
    "\n",
    "    # create the index metadata\n",
    "    metadata = struct_pb2.Struct(fields={\n",
    "        \"config\": struct_pb2.Value(struct_value=index_config),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(string_value=BUCKET_NAME+\"/vector_embeddings/\"),\n",
    "            })\n",
    "\n",
    "    # enable stream update or batch update\n",
    "    if stream_update:\n",
    "        index = {\n",
    "            \"display_name\": DISPLAY_NAME,\n",
    "            \"description\": \"stream update\",\n",
    "            \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "            \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.STREAM_UPDATE,\n",
    "            }\n",
    "    else:#batch update\n",
    "        index = {\n",
    "            \"display_name\": DISPLAY_NAME,\n",
    "            \"description\": \"batch update\",\n",
    "            \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "            \"index_update_method\": aiplatform_v1.Index.IndexUpdateMethod.BATCH_UPDATE,\n",
    "                }\n",
    "\n",
    "    # submit create index request\n",
    "    created_index = index_client.create_index(parent=PARENT, index=index)\n",
    "    # poll the job update logs\n",
    "    while True:\n",
    "        if created_index.done():\n",
    "            break\n",
    "        logging.info(\"Poll the operation to create index...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06cddd9-61c7-4394-8d11-9e74ed78a7e4",
   "metadata": {},
   "source": [
    "<h3>Create an endpoint for deployment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8912eb-c6f5-4348-9619-0cc155b1417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vpc_network = \"projects/543051426883/global/networks/default\" # format is like 'projects/{project_number}/global/networks/{network_name}'\n",
    "\n",
    "# create an endpoint \n",
    "index_endpoint_client = aiplatform_v1.IndexEndpointServiceClient(\n",
    "        client_options=dict(api_endpoint=ENDPOINT)\n",
    "    )\n",
    "\n",
    "\n",
    "index_endpoint = {\n",
    "        \"display_name\": DISPLAY_NAME + \"_endpoint\",\n",
    "        \"network\": vpc_network,\n",
    "    }\n",
    "\n",
    "r = index_endpoint_client.create_index_endpoint(\n",
    "        parent=PARENT, index_endpoint=index_endpoint\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0014c3-805a-4ff2-ad2f-7852c44a8cd8",
   "metadata": {},
   "source": [
    "<h3>Deploy the index to the endpoint</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44011a34-b7bf-4b1c-bdc4-c3d4d6c5fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the index to the endpoint for querying\n",
    "index =\"3920964017765482496\"\n",
    "\n",
    "INDEX_ENDPOINT_NAME = r.result().name\n",
    "DEPLOYED_INDEX_ID = DISPLAY_NAME + \"_deployed_index\"\n",
    "INDEX_RESOURCE_NAME = \"projects/543051426883/locations/us-west1/indexes/\"+index #created_index.result().name # format is like 'projects/{project_number}/locations/{location}/indexes/{index_id}'\n",
    "\n",
    "deploy_index = {\n",
    "        \"id\": DEPLOYED_INDEX_ID,\n",
    "        \"display_name\": DEPLOYED_INDEX_ID,\n",
    "        \"index\": INDEX_RESOURCE_NAME,\n",
    "    }\n",
    "\n",
    "# submit the deploy index request\n",
    "my_index_endpoint = index_endpoint_client.deploy_index(\n",
    "        index_endpoint=INDEX_ENDPOINT_NAME, deployed_index=deploy_index\n",
    "    )\n",
    "# Poll the operation until it's done successfullly.\n",
    "\n",
    "while True:\n",
    "    if my_index_endpoint.done():\n",
    "        break\n",
    "    print(\"Poll the operation to deploy index...\")\n",
    "    time.sleep(60)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc24ff-b290-4827-8853-bd987d9b1e5e",
   "metadata": {},
   "source": [
    "<h3>Query the index</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109e1e53-e8a0-4dda-86b1-c9b3f96a06a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='https://www.huffingtonpost.com/entry/kentucky-voting-rights_us_5654806be4b0258edb32ebdc', distance=0.204626202583313),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/felon-voting-rights-restoration_us_5655de80e4b079b28189da1e', distance=0.44457077980041504),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/virginia-felons-voting-rights_us_57bb354ce4b0b51733a4d9f6', distance=0.5083640217781067),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/rick-scott-felon-disenfranchisement_us_5ac50856e4b09ef3b242f45f', distance=0.512243390083313),\n",
       "  MatchNeighbor(id='https://www.huffpost.com/entry/florida-former-felons-vote-restored_n_5c332425e4b0bcb4c25da9b6', distance=0.5165200233459473),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/felony-voting-laws-are-confusing-activists-would-ditch_us_5ac6371ce4b01190c1ed6e41', distance=0.5221322178840637),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/alabama-felon-moral-turpitude_us_597ce859e4b02a4ebb75d693', distance=0.5221430659294128),\n",
       "  MatchNeighbor(id='https://www.huffpost.com/entry/florida-felons-vote-unpaid-fines-fees_n_5e4e1e24c5b630e74c504927', distance=0.528042733669281),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/louisiana-felon-disenfranchisement-voting-rights_us_5afc9888e4b06a3fb50d46cc', distance=0.5298784375190735),\n",
       "  MatchNeighbor(id='https://www.huffingtonpost.com/entry/new-jersey-prisoners-to-vote_us_5a942b9be4b01f65f598c58e', distance=0.5318239331245422)]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Query the index\n",
    "from google.cloud import aiplatform\n",
    "# DEPLOYED_INDEX_ID = \"similar_article_index_deployed_index\"\n",
    "idx_enpoint = \"projects/penguins-mbagaya/locations/us-west1/indexEndpoints/6777160975192686592\" #r.result().name\n",
    "\n",
    "\n",
    "candidates_embedding = [[0.0502016456, -0.099912588, -0.8578929521, -0.035492491, -0.0298160315, 0.0578172, -0.0591950715, 0.00769451866, 0.0521428809, -0.0768064186, -0.0360548832, 0.0511014275, 0.0607668199, -0.0167274252, 0.0278223436, -0.0733504072, -0.0553152338, 0.011630984, -0.0372170731, -0.03048319, -0.0561569594, 0.0393138938, 0.0769464225, 0.0459631607, 0.0162670016, 0.0580527596, -0.0380507633, 0.0437482595, -0.0216746423, -0.0175770447, -0.0174269807, 0.00592250936, 0.0195918, -0.0434573852, 0.0215063971, 0.0380142666, 0.0627181679, -0.00142126402, -0.0280464888, 0.081744507, 0.0385259166, -0.0194710102, 0.00883859769, 0.0104368478, 0.0115294335, 0.0502061024, 0.0377715714, -0.0470889807, 0.0254153796, -0.0689847767, -0.0717464909, -0.06491, 0.0126711708, 0.0112836855, -0.0541676097, -0.0356421433, -0.0164782982, -0.0610802695, 0.0423853733, 0.0488026142, -0.0289505068, -0.000677486591, -0.0476895459, 0.00380550791, -0.0596526153, -0.00640337588, -0.0220143981, 0.0359431, 0.0322990753, -0.0474538691, 0.054927133, -0.00737987272, 0.0140833808, 0.0443712324, -0.043933779, 0.0409256071, 0.00772624137, -0.0229224265, -0.0722916, 0.0597278886, -0.0442352816, 0.00616668351, 0.000982288155, 0.0568430573, -0.060338337, 0.0552312955, 0.00631992472, -0.0821219385, 0.0561952889, 0.0680704713, 0.0169057455, -0.0601352453, -0.00401292695, 0.0737325177, -0.0767178312, 0.0433958881, 0.0168477539, -0.0603372641, 0.0803615153, -0.0396288484, 0.00747376308, 0.0123901023, -0.0492022783, -0.0297769308, 0.0600016415, 0.0327744, -0.0383736119, 0.00626307772, 0.075845331, 0.0704802126, -0.019431429, 0.0147908265, 0.0115813557, 0.051621, 0.00542780757, 0.0571184829, 0.0614894032, -0.0470786393, 0.0623328239, -0.052912388, -0.0170839764, 0.00801151618, -0.039427653, 0.0572161525, 0.00167220051, 0.0406115353, 0.042143587, 0.0578572936, 0.00313223619, -0.0323182568, -0.0586032756, -0.0639747679, -0.00879042, -0.00917307194, 0.0182663631, 0.0175092723, -0.0254115406, 0.00019361559, -0.0317655206, -0.0563735217, 0.078452155, 0.0507345274, 0.0173529927, -0.0490901545, -0.0822084844, 0.081648849, 0.0261113588, -0.0563871451, -0.0518015586, -0.0348771252, -0.0398101844, -0.0139666991, 0.0184999667, -0.0375076868, 0.0602380857, -0.0249493979, 0.0734049156, -0.0512630902, 0.0289901346, 0.0765650347, -0.0669102296, -0.0722649768, -0.0313954577, 0.0154615585, -0.00943078, 0.0787919909, 0.0673941597, 0.0311770607, 0.0354374647, -0.0265306365, 0.0437518097, -0.0732665658, 0.0489297248, 0.0655555576, -0.0393787138, -0.0388070829, 0.00970042683, -0.0311868507, -0.0827492177, -0.0206832308, -0.0519809723, -0.00493504945, -0.0685245842, -0.0282617398, 0.0355950221, -0.00734898634, 0.0376003645, 0.0253161155, 0.0584747083, 0.0212987959, -0.0384559371, 0.082592912, 0.0311547089, 0.0624623373, -0.0814144462, 0.0395354666, -0.0231002867, 0.0421228856, -0.0316452384, 0.00487433653, 0.081918, 0.0544711351, -0.0105061373, -0.0656491295, 0.0633879, 0.0184279773, 0.0244700145, -0.0186490659, 0.0489147231, -0.0642368719, -0.0202094428, 0.0435244404, 0.0441161953, -0.0397966728, 0.00379270967, -0.0826089457, -0.0361774899, 0.0148726385, 0.062031, 0.0274232719, 0.0018814319, -0.0396838896, -0.00243198988, 0.0693733543, 0.0090195518, -0.0290311389, 0.0483087078, 0.0133154988, -0.00168000278, 0.0018319498, 0.0636196136, -0.00776374154, -0.0360434279, -0.0814935938, -0.0158276167, 0.076635845, 0.0709537119, 0.031912, 0.0192611646, -0.0020914129, -0.0175421238, -0.0556306057, 0.0562396981, -0.0131248496, -0.0311832521, -0.0389447063, 0.0081713954, -0.0650436059, -0.0728608742, 0.0381941162, 0.0728306696, -0.0333044268, -0.0498978645, 0.0464298204, 0.0603470914, 0.0245335829, -0.0466825403, 0.0367866494, 0.0354647525, 0.0224961024, 0.00907058641, 0.0262220241, 0.00287109287, -0.0202807207, -0.0611601658, -0.0140948519, -0.0241945963, 0.0169137083, 0.04755513, -0.072648935, -0.0248457938, 0.0134985298, 0.0326770581, -0.0753605962, 0.0431795977, 0.0070912689, 0.0538257435, -0.0551753193, 0.0802449882, -0.0442277, 0.0728385448, 0.0388735756, 0.0478703529, 0.0146021023, -0.0253923088, -0.0707472, -0.0463880636, 0.0812347755, -0.0660555139, 0.0275677182, 0.074266471, -0.00873696245, 0.0740572587, 0.0300100874, 0.0488660261, 0.00390042644, 0.0183884613, 0.0513804667, -0.0134160146, 0.0104410294, -0.0548431613, 0.00267668464, -0.0045957393, -0.0431737155, 0.0447403081, 0.0280321818, 0.0606655292, -0.044766, 0.00433506304, 0.0612494163, -0.0300246403, -0.0127954045, 0.0151460106, -0.0455670394, -0.0663784593, -0.0198004544, -0.0314645022, -0.0233538225, 0.0375389, 0.0419015922, 0.0114331888, -0.0567778945, -0.0205252562, 0.0640368462, 0.0304049719, 0.0418470241, 0.0718007684, 0.0249215048, 0.0485383123, 0.0256850589, 0.0161422547, -0.0715882853, -0.031735085, 0.00729028787, -0.0248725768, -0.0534334667, -0.00668986514, -0.0530478396, 0.0210357681, -0.0808970109, 0.0302360952, -0.0505049229, 0.000117966345, 0.0827040151, 0.01088777, -0.0417144224, -0.050915949, 0.0712650046, -0.0804398507, 0.013461112, -0.0690629, 0.0565128922, 0.0593511537, 0.054564774, 0.00770380441, 0.0287936367, -0.0799678564, 0.0595743619, -0.0295372885, 0.0749069, -0.0206449535, -0.0704574063, 0.0716846809, 0.0305647962, 0.0119375754, 0.0403936505, 0.0181931518, -0.0112507623, 0.0250820667, 0.0193080865, -0.00632366771, -0.0114755929, -0.062191505, 0.0511554033, 0.0264797751, -0.04922387, 0.067763187, 0.0448058881, -0.0122261066, -0.0782086775, -0.0218615942, 0.0469329022, -0.0729536265, 0.039681755, 0.0633885041, 0.0739140883, 0.000466615224, 0.00981137808, 0.0484512709, -0.0618514754, -0.0511878841, -0.0678248182, 0.0320391618, 0.0265220441, 0.0426274426, -0.0408450514, -0.0365734622, 0.0174115263, -0.0102628972, -0.0563230067, 0.029912306, 0.0348706208, -0.0441398956, 0.0484397821, -0.00193183741, -0.053231325, -0.0031785618, 0.0546823815, -0.0622022822, -0.0735706, 0.00255643437, -0.0140257142, -0.00473003043, 0.0171921067, -0.0228456222, 0.0364877656, 0.0294562951, 0.0120815663, -0.00332700461, -0.0322813839, -0.0772143155, -0.0101970853, -0.0344852097, -0.0511004366, -0.059917938, -0.0165633541, 0.00150151621, 0.0252316985, -0.0292765591, 0.0350353047, 0.0313969888, -0.037920475, -0.0100262454, 0.0595380031, 0.0212509129, 0.00227843691, 0.0123936273, -0.0618601, -0.0711660236, -0.0463614725, -0.0176716968, -0.041117616, 0.0501014404, 0.0740635619, 0.0316318125, 0.0319646634, -0.041036129, -0.0492766201, -0.0410203375, 0.0154050356, 0.00724651804, -0.00200869422, 0.0144809075, -0.00493975263, -0.0142480489, 0.00977388769, -0.0168318432, 0.0133904684, -0.0764209, 0.0188833009, 0.0278521795, 0.0216211285, 0.0184155144, 0.0710755959, -0.0332404673, 0.0428488292, 0.0556732714, -0.0496581122, -0.018820351, -0.0691318437, -0.0581589, 0.0407969728, -0.0256147366, 0.0421869494, -0.00859052, -0.0579928793, 0.0408137292, 0.0261646267, 0.000727738428, 0.0523216, -0.00628263596, 0.00592074869, 0.00385966455, -0.0548521131, -0.0591544136, 0.0423886739, 0.0418718494, -0.00265934318, -0.000706568069, -0.0224871896, -0.0124037191, -0.0377913229, -0.031713672, 0.00600458356, 0.0358984321, -0.0611761697, 0.0498134196, 0.0270567555, -0.0348888636, -0.0337959, -0.0809504, -0.0481201671, -0.0369402543, 0.0323536061, -0.0332562253, 0.0485725701, -0.0484549701, 0.0437381528, 0.00597401569, 0.0328890048, -0.0480710231, 0.0604506582]]\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\"6777160975192686592\", location=\"us-west1\")\n",
    "\n",
    "response = my_index_endpoint.match(deployed_index_id=DEPLOYED_INDEX_ID, queries=candidates_embedding, num_neighbors=10)\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
